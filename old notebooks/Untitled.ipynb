{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f602115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed06e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8509d8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /ifxhome/manna/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# lemmatization\n",
    "if initialize:\n",
    "    nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f7ba49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9581 entries, 0 to 9580\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Ticketid                    9581 non-null   object\n",
      " 1   Calendar Week               9581 non-null   object\n",
      " 2   Ticket Created Time         9581 non-null   object\n",
      " 3   Priority                    9581 non-null   object\n",
      " 4   Site                        9581 non-null   object\n",
      " 5   Problem Description         9581 non-null   object\n",
      " 6   General Category            9581 non-null   object\n",
      " 7   Sub Category                9581 non-null   object\n",
      " 8   Resolution                  9581 non-null   object\n",
      " 9   Customer Department         9581 non-null   object\n",
      " 10  Predicted General Category  9581 non-null   object\n",
      " 11  Predicted Sub Category      9581 non-null   object\n",
      " 12  Input                       9581 non-null   object\n",
      " 13  Lot Number                  9581 non-null   object\n",
      "dtypes: object(14)\n",
      "memory usage: 1.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tickets = pd.read_excel('Ticket Details.xlsx', header=1 , sheet_name = \"Sheet 1\", names=['Ticketid', 'Calendar Week', 'Ticket Created Time', 'Priority', 'Site', 'Problem Description', 'General Category', 'Sub Category', 'Resolution', 'Customer Department', 'Predicted General Category', 'Predicted Sub Category'])\n",
    "#tickets.columns = tickets.columns.str.strip()\n",
    "tickets['Input'] = np.nan\n",
    "tickets['Lot Number'] = np.nan\n",
    "tickets = tickets.fillna('')\n",
    "print(tickets.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfceb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words = words.words()\n",
    "valid_words = ['dn', 'alf', 'jcbe', 'stms']\n",
    "corpus_words.append(valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31860da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.stem.porter.PorterStemmer()\n",
    "lem = nltk.stem.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4e201f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dn', 'alf', 'jcbe', 'stms']\n"
     ]
    }
   ],
   "source": [
    "print(valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1a61a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /ifxhome/manna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append([r'infineon',\n",
    "    r'com'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ada3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words but phrases, used to remove pointless words, unnecessary if TF-IDF is used\n",
    "remove_phrases = [r'(1)',\n",
    "    r'(2)',\n",
    "    r'(3)',\n",
    "    r'(4)',\n",
    "    r'(5)',\n",
    "    r'(6)',\n",
    "    r'(7)',\n",
    "    r'(8)',\n",
    "    r'(9)',\n",
    "    r'(10)',\n",
    "    r'(11)',\n",
    "    r'problem description on error*: (including screenshot of error)',\n",
    "    r'site*: mark \"x\" for user site',\n",
    "    r'[ x ]',\n",
    "    r'[  ] bth',\n",
    "    r'[  ] mkz plt',\n",
    "    r'[  ] wux cc',\n",
    "    r'[  ] tij',\n",
    "    r'[  ] sin',\n",
    "    r'[  ] mkz scc',\n",
    "    r'[  ] wux ds',\n",
    "    r'[  ] rbg',\n",
    "    r'[  ] mkz pla',\n",
    "    r'[  ] wux hps',\n",
    "    r'[  ] cjj',\n",
    "    #r'Lot Number:',\n",
    "    #r'equipments affected:',\n",
    "    r'equipment/pc name:',\n",
    "    r'camstar server*:',\n",
    "    r'https://faqstorage.infineon.com/knowledgebasearticle125028.aspx',\n",
    "    r'integration application: mark \"x\" for other application', \n",
    "    r'[  ] awi',\n",
    "    r'[  ] gpn',\n",
    "    r'[  ] xmes',\n",
    "    r'[  ] ddm',\n",
    "    r'[  ] stms',\n",
    "    r'[  ] xtest ui',\n",
    "    r'[  ] eaf',\n",
    "    r'[  ] workstream',\n",
    "    r'printer:',\n",
    "    r'https://faqstorage.infineon.com/knowledgebasearticle125029.aspx',\n",
    "    r'referred to faq*:',\n",
    "    r'affected area contact number*:',\n",
    "    r'alt contact person name (compulsory for critical)*:', \n",
    "    r'alt contact person number (compulsory for critical):',\n",
    "    r'* mandatory fields.',\n",
    "    r'contactnumber:',\n",
    "    r'affected area contact number:',\n",
    "    r'requestor department:',\n",
    "    r'problem description:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a84da7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the regex input to clean up the template for non words\n",
    "regex_remove_punctuations = r'[~`!@#\\$%\\^&\\*\\(\\)_\\+\\-\\=\\{\\}\\|\\[\\]\\\\:;\"\\'<>\\?,\\.\\/]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0164f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_correction(problem_description, resolution):\n",
    "    corrected_text = \"\"\n",
    "    input_words = word_tokenize(problem_description.lower() + ' ' + resolution.lower())\n",
    "    for input_word in input_words:\n",
    "        '''\n",
    "        if input_word not in valid_words or input_word not in corpus_words:\n",
    "            corrected_word = [(jaccard_distance(set(ngrams(input_word, 2)), set(ngrams(corpus_word, 2))), corpus_word) \\\n",
    "                    for corpus_word in corpus_words if corpus_word[0] == input_word[0]]\n",
    "            corrected_text += corrected_word[0]\n",
    "        '''\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab221910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_extract(problem_description, resolution):\n",
    "    text = problem_description.lower() + ' ' + resolution.lower()\n",
    "    # replace newline and tab with whitespace\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    # these 2 lines remove all the common templates, by right they should not matter if fed into TF-IDF\n",
    "    for substring in remove_phrases:\n",
    "        text = text.replace(substring, ' ')\n",
    "    # remove punctuations using regex\n",
    "    text = re.sub(regex_remove_punctuations, ' ', text)\n",
    "    # remove duplicate white space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text_list = word_tokenize(text)\n",
    "    # remove stop words\n",
    "    text_list = [lem.lemmatize(word) for word in text_list]\n",
    "    text_list = [word for word in text_list if not word in stop_words]\n",
    "    corrected_text = []\n",
    "    '''\n",
    "    for input_word in text_list:\n",
    "        if input_word not in valid_words or input_word not in corpus_words:\n",
    "            corrected_word = [(jaccard_distance(set(ngrams(input_word, 2)), set(ngrams(corpus_word, 2))), corpus_word) \\\n",
    "                    for corpus_word in corpus_words if corpus_word[0] == input_word[0]]\n",
    "            try:\n",
    "                corrected_text.append(corrected_word[0])\n",
    "            except:\n",
    "                corrected_text.append(input_word)\n",
    "                '''\n",
    "    text = TreebankWordDetokenizer().detokenize(text_list)\n",
    "    # separate lot number for RPA purposes\n",
    "    try:\n",
    "        #text = re.sub(r'(?=product).*(?=equipment affected)', '', text)\n",
    "        lot_number = re.search(r'(?<=lot number ).*(?= equipment affected)', text).group(0).upper()\n",
    "        #text = re.sub(r'(lot number ).*( equipment affected)', '', text)\n",
    "    except:\n",
    "        lot_number = np.nan\n",
    "    return pd.Series([text, lot_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45856fc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tickets[['Input', 'Lot Number']] = tickets.apply(lambda row: clean_extract(row['Problem Description'], row['Resolution']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "634608d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INC000004851509\n",
      "error trackout 0 camstar lotsplitbyitems splitlot e0100 za942324m0j total ndpw item qty doe match lot qty lot number za942324m0j equipment affected stp03 6062515654 iscw8cc938477d infineon com 172 21 97 9 infineon alismoha mkz investigation using script see many total item qty v lot qty select sum ndpw lotwafers containerid select containerid container containername za942324m0j match lot qty sum item qty bypass singulate\n",
      "ZA942324M0J\n"
     ]
    }
   ],
   "source": [
    "# these 9 examples are the best for button greyed out, look at all the different phrasings\n",
    "print(tickets['Ticketid'][1])\n",
    "print(tickets['Input'][1])\n",
    "print(tickets['Lot Number'][1])\n",
    "# print()\n",
    "# print(tickets['Ticketid'][135])\n",
    "# print(tickets['Input'][135])\n",
    "# print(tickets['Lot Number'][135])\n",
    "# print()\n",
    "# print(tickets['Ticketid'][136])\n",
    "# print(tickets['Input'][136])\n",
    "# print(tickets['Lot Number'][136])\n",
    "# print()\n",
    "# print(tickets['Ticketid'][234])\n",
    "# print(tickets['Input'][234])\n",
    "# print(tickets['Lot Number'][234])\n",
    "# print()\n",
    "# print(tickets['Ticketid'][235])\n",
    "# print(tickets['Input'][235])\n",
    "# print(tickets['Lot Number'][235])\n",
    "# print()\n",
    "# print(tickets['Ticketid'][236])\n",
    "# print(tickets['Input'][236])\n",
    "# print(tickets['Lot Number'][236])\n",
    "# print()\n",
    "# print(tickets['Ticketid'][5134])\n",
    "# print(tickets['Input'][5134])\n",
    "# print(tickets['Lot Number'][5134])\n",
    "# print()\n",
    "# print(tickets['Ticketid'][5135])\n",
    "# print(tickets['Input'][5135])\n",
    "# print(tickets['Lot Number'][5135])\n",
    "# print()\n",
    "# print(tickets['Ticketid'][5136])\n",
    "# print(tickets['Input'][5136])\n",
    "# print(tickets['Lot Number'][5136])\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0424658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticketid</th>\n",
       "      <th>Calendar Week</th>\n",
       "      <th>Ticket Created Time</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Site</th>\n",
       "      <th>Problem Description</th>\n",
       "      <th>General Category</th>\n",
       "      <th>Sub Category</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Customer Department</th>\n",
       "      <th>Predicted General Category</th>\n",
       "      <th>Predicted Sub Category</th>\n",
       "      <th>Input</th>\n",
       "      <th>Lot Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Ticketid, Calendar Week, Ticket Created Time, Priority, Site, Problem Description, General Category, Sub Category, Resolution, Customer Department, Predicted General Category, Predicted Sub Category, Input, Lot Number]\n",
       "Index: []"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets[tickets['Ticketid']==\"INC000004851282\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "045f601c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1) Problem description on error*: (Including screenshot of error) \\nThe FAJob : ZA940359M0XSPAV0420200908134433329 does not belong to this Equipment: SPTV01\\n\\n(2) Site*: Mark \"x\" for user site\\n\\n[  ] BTH \\t\\t\\t[  ] MKZ PLT\\t\\t[  ] WUX CC\\t\\t[  ] TIJ\\n[  ] SIN \\t\\t\\t[X] MKZ SCC\\t        [  ] WUX DS\\t\\t[  ] RBG \\t\\t\\n[  ] MKZ PLA\\t\\t[  ] WUX HPS\\t\\t[  ] CJJ     \\n\\n(3) Lot Number: ZA940359M0X\\n\\n(4) Equipments affected:  SPTV01\\n\\n(5) Equipment/PC name:ISCN5CG0289G0D\\n\\n(6) Camstar Server*:\\nhttps://faqstorage.infineon.com/KnowledgebaseArticle125028.aspx\\n\\n(7) Integration application: Mark \"x\" for other application\\n \\n[  ] AWI\\t\\t\\t[  ] GPN\\t\\t\\t[  ] XMES  \\t   \\n[  ] DDM\\t\\t\\t[  ] StMS\\t\\t        [  ] XTEST UI  \\n[  ] EAF\\t\\t\\t[  ] Workstream  \\t  \\n \\n(8) Printer:\\nhttps://faqstorage.infineon.com/KnowledgebaseArticle125029.aspx\\n\\n(9) Referred to FAQ*: no faq found\\n\\n(10)Affected area contact number*:  +0172907259 / +60 6 251 8844\\n\\n* Mandatory fields.  ISCN5CG0289G0D.infineon.com, 10.245.8.198, INFINEON\\\\TanJinSu, MKZ/DC.G.R01.GE262, ,'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets['Problem Description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50834906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3712ba78",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "input must have more than one sentence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10845/588159429.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m## Apply the function to corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10845/588159429.py\u001b[0m in \u001b[0;36mtextrank\u001b[0;34m(corpus, ratio)\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     lst_summaries = [gensim.summarization.summarize(txt,  \n\u001b[0;32m----> 6\u001b[0;31m                      ratio=ratio) for txt in corpus]    \n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlst_summaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10845/588159429.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     lst_summaries = [gensim.summarization.summarize(txt,  \n\u001b[0;32m----> 6\u001b[0;31m                      ratio=ratio) for txt in corpus]    \n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlst_summaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/summarization/summarizer.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, ratio, word_count, split)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;31m# If only one sentence is present, the function raises an error (Avoids ZeroDivisionError).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input must have more than one sentence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;31m# Warns if the text is too short.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: input must have more than one sentence"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "def textrank(corpus, ratio=0.2):    \n",
    "    if type(corpus) is str:        \n",
    "       corpus = [corpus]    \n",
    "    lst_summaries = [gensim.summarization.summarize(txt,  \n",
    "                     ratio=ratio) for txt in corpus]    \n",
    "    return lst_summaries\n",
    "\n",
    "## Apply the function to corpus\n",
    "predicted = textrank(corpus=text, ratio=0.2)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78e733df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fajob za940359m0xspav0420200908134433329 doe belong equipment sptv01 x mkz scc lot number za940359m0x equipment affected sptv01 iscn5cg0289g0d faq found 0172907259 60 6 251 8844 iscn5cg0289g0d infineon com 10 245 8 198 infineon tanjinsu mkz dc g r01 ge262'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def clean_extrpact(problem_description, resolution):\n",
    "text = tickets['Problem Description'][0].lower()\n",
    "# replace newline and tab with whitespace\n",
    "text = text.replace('\\n', ' ')\n",
    "text = text.replace('\\t', ' ')\n",
    "# these 2 lines remove all the common templates, by right they should not matter if fed into TF-IDF\n",
    "for substring in remove_phrases:\n",
    "    text = text.replace(substring, ' ')\n",
    "# remove punctuations using regex\n",
    "text = re.sub(regex_remove_punctuations, ' ', text)\n",
    "# remove duplicate white space\n",
    "text = re.sub(' +', ' ', text)\n",
    "text_list = word_tokenize(text)\n",
    "# remove stop words\n",
    "text_list = [lem.lemmatize(word) for word in text_list]\n",
    "text_list = [word for word in text_list if not word in stop_words]\n",
    "# corrected_text = []\n",
    "'''\n",
    "for input_word in text_list:\n",
    "    if input_word not in valid_words or input_word not in corpus_words:\n",
    "        corrected_word = [(jaccard_distance(set(ngrams(input_word, 2)), set(ngrams(corpus_word, 2))), corpus_word) \\\n",
    "                for corpus_word in corpus_words if corpus_word[0] == input_word[0]]\n",
    "        try:\n",
    "            corrected_text.append(corrected_word[0])\n",
    "        except:\n",
    "            corrected_text.append(input_word)\n",
    "            '''\n",
    "text = TreebankWordDetokenizer().detokenize(text_list)\n",
    "# separate lot number for RPA purposes\n",
    "# try:\n",
    "    #text = re.sub(r'(?=product).*(?=equipment affected)', '', text)\n",
    "#         lot_number = re.search(r'(?<=lot number ).*(?= equipment affected)', text).group(0).upper()\n",
    "    #text = re.sub(r'(lot number ).*( equipment affected)', '', text)\n",
    "# except:\n",
    "#     lot_number = np.nan\n",
    "#     return pd.Series([text, lot_number])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85532783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0ee3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74265198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL | 20375\n",
      "CARDINAL | 203\n"
     ]
    }
   ],
   "source": [
    "phrase_matcher = PhraseMatcher(nlp.vocab)\n",
    "phrases = ['button','grey']\n",
    "patterns = [nlp(i) for i in text]\n",
    "phrase_matcher.add('button',None, *patterns)\n",
    "\n",
    "doc = nlp(text[:100])\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print(entity.label_, '|', entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6383cad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'move lot strip map total qty 20375 doe match lot qty 20379 user request camstar admin adjust qty 203'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c0e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 C2M8 Oracle",
   "language": "python",
   "name": "p3-c2m8-g0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
